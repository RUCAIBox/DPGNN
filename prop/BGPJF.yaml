# Model
embedding_size: 256
n_layers: 3
# reg_weight: 1e-05
# hidden_size: 8
# dropout: 0.2

ADD_B_LOSS: False
ADD_M_LOSS: False
ADD_BERT: False
BERT_embedding_size: 768
BERT_output_size: 32

sample_n: 5

lambda_1: 0.1
lambda_2: 0.1

# Training
learning_rate: 0.0003

# General
train_batch_size: 4096
eval_batch_size: 4096

